{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0afd5654-1215-4b50-86b3-5eedb5dbc787",
   "metadata": {},
   "source": [
    "### Some scripts for reviewing UD Swedish LinES data and changing values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d18aa38-e631-4389-b7f6-8077e6106055",
   "metadata": {},
   "source": [
    "In this notebook I develop scripts that detects violations of current UD guidelines and, if possible, perform automatic conversions to the recommended analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9d1730dc-00ca-4d39-8b86-1fdd05ec5279",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re, os\n",
    "from collections import defaultdict, Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4721f9a-8262-4c19-a62a-6f4f1dc0d5c6",
   "metadata": {},
   "source": [
    "Files can be obtained from here -- change these to your own environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e70598ab-ccde-47f8-8600-f46356d7b1c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found file: sv_talbanken-ud-dev.conllu\n",
      "Found file: sv_talbanken-ud-test.conllu\n",
      "Found file: sv_talbanken-ud-train.conllu\n"
     ]
    }
   ],
   "source": [
    "udpath = '/home/norrman/GitHub/UD_Swedish-Talbanken/not-to-release/output/'\n",
    "talbfiles = ['sv_talbanken-ud-dev.conllu', 'sv_talbanken-ud-test.conllu', 'sv_talbanken-ud-train.conllu']\n",
    "\n",
    "for tbf in talbfiles:    \n",
    "    if os.path.exists(udpath+tbf):\n",
    "        print(f'Found file: {tbf}')\n",
    "    else:\n",
    "        print(f'ERROR - File not found: {tbf}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf937e3f-f6a9-45ee-a8a7-547227c059e2",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Extracting and counting tokens with simple conditions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fcf94df3-0829-42a8-bc5c-328cfb913d4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0: ID, 1: FORM, 2: LEMMA, 3: UPOS, 4: XPOS, 5: FEATS, 6: HEAD, 7: DEPREL, 8: ENHANCED-DEPS, 9: MISC\n",
    "\n",
    "def getMweStatsInTreebank (treebankpath, treebanks, deprel):\n",
    "    ''' returns frequency for a given deprel in a set of treebanks '''\n",
    "    nmboftokens = 0\n",
    "    nmbofdeprels = 0\n",
    "    for tb in treebanks:\n",
    "        print(tb)\n",
    "        with open(treebankpath + tb, \"r\") as t:\n",
    "            for line in t:\n",
    "                if re.match(r'# sent_id', line):\n",
    "                    headsfound = []\n",
    "                elif re.match(r'\\d', line):\n",
    "                    nmboftokens += 1\n",
    "                    info = line.strip().split()\n",
    "                    if info[7] == deprel:\n",
    "                        nmbofdeprels += 1\n",
    "                        headsfound.append(info[6])\n",
    "                elif (len(line)<2) and (len(headsfound)>0): # empty line\n",
    "                    headset = set(headsfound)\n",
    "                    nmbofdeprels += len(headset)\n",
    "                                                        \n",
    "    return nmboftokens, nmbofdeprels\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5caf92ce-b753-4055-8d90-4ab710586612",
   "metadata": {},
   "source": [
    "An example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8edcf005-633f-465c-830a-1dc74d69369e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sv_talbanken-ud-dev.conllu\n",
      "sv_talbanken-ud-test.conllu\n",
      "sv_talbanken-ud-train.conllu\n"
     ]
    }
   ],
   "source": [
    "tokennmbs, fixednmbs = getMweStatsInTreebank (udpath, talbfiles, 'fixed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "79370784-2784-4aaf-853a-9d6714b85a72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Included tokens: 3018 Total tokens: 96859\n",
      "Fixed MWE share: 0.0312 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Included tokens:', fixednmbs, 'Total tokens:', tokennmbs)\n",
    "print('Fixed MWE share:', round((fixednmbs / tokennmbs), 4), '\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "385ddf77-0866-40d4-9282-b27482df9680",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0: ID, 1: FORM, 2: LEMMA, 3: UPOS, 4: XPOS, 5: FEATS, 6: HEAD, 7: DEPREL, 8: ENHANCED-DEPS, 9: MISC\n",
    "\n",
    "def getTokensByInfo (udfile, poscat, feats):\n",
    "    ''' returns a list of tokens matching a feature description exactly '''\n",
    "    retlist = []\n",
    "    with open (udfile, \"r\") as u:\n",
    "        for line in u:\n",
    "            if re.match(r'# sent_id', line):\n",
    "                sentid = line.split('=')[-1].strip()\n",
    "            elif re.match(r'\\d', line):\n",
    "                info = line.split('\\t')\n",
    "                # print(f\"{info[3]=}, {info[5]=}\")\n",
    "                if (info[3] == poscat) and (info[5] == feats): # a match\n",
    "                    match = [sentid, info[1], info[0]]\n",
    "                    retlist.append(match)\n",
    "    return retlist\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "953e1e54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['sv-ud-dev-9', 'sköterskor', '14'],\n",
       " ['sv-ud-dev-10', 'föräldrar', '11'],\n",
       " ['sv-ud-dev-12', 'försummelser', '13']]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens = getTokensByInfo(udpath+talbfiles[0], 'NOUN', 'Case=Nom|Definite=Ind|Gender=Com|Number=Plur')\n",
    "\n",
    "tokens[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cd51a86-d176-48e3-aa63-4b60f2f4b59c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compareLemmas (udpath + svlinesfiles[0], udpath + talbfiles[0], 'PRON')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f951845b-8b14-4e94-bc3e-77751d18fced",
   "metadata": {},
   "source": [
    "### Finding all descriptions for a list of tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "dfab4938-02b8-448d-9e45-27e2e4d91b1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0: ID, 1: FORM, 2: LEMMA, 3: UPOS, 4: XPOS, 5: FEATS, 6: HEAD, 7: DEPREL, 8: ENHANCED-DEPS, 9: MISC\n",
    "\n",
    "def findDescriptions (path, corpus, tokenlist):\n",
    "    ''' returns a dictionary of alternative feature descriptions for a list of tokens '''\n",
    "    result = defaultdict()\n",
    "    for corp in corpus:\n",
    "        udfile = path + corp\n",
    "        with open(udfile, \"r\") as u:\n",
    "            for line in u:    \n",
    "                if re.match(r'\\d', line):\n",
    "                    info = line.split('\\t')\n",
    "                    # compute the result as lemma_upos_feats\n",
    "                    entry = info[1].lower()\n",
    "                    if entry in tokenlist:\n",
    "                        descr = info[1] + ', Lemma=' + info[2] + ', UPOS=' + info[3] + ', FEATS=' + info[5]\n",
    "                        try:\n",
    "                            result[entry][descr] += 1\n",
    "                        except:\n",
    "                            try:\n",
    "                                result[entry][descr] = 1\n",
    "                            except:\n",
    "                                result[entry] = Counter()\n",
    "                                result[entry][descr] = 1\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c1a6b766-a825-420d-9fd4-07ddd9bc278f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example\n",
    "tottokens = ['all', 'alla', 'allt', 'båda', 'bägge', 'halv', 'halva', 'halvt', 'hel', 'hela', 'helt', 'varje']\n",
    "#totdict = findDescriptions(udpath, svlinesfiles, tottokens)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df04c5e1-29c8-413d-bcb7-49202f0216c6",
   "metadata": {},
   "source": [
    "### Extracting and changing lemmas and features for the words *de, den, det*."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5d06089-b7ca-4c81-8c36-3e65378fe835",
   "metadata": {},
   "source": [
    "We can check the current features by using *findDescriptions*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "765b6330-7ca7-4d28-b8d8-0415805335f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "de, Lemma=en, UPOS=DET, FEATS=Definite=Def|Number=Plur|PronType=Art 505\n",
      "de, Lemma=de, UPOS=PRON, FEATS=Case=Nom|Definite=Def|Number=Plur|PronType=Prs 278\n",
      "De, Lemma=en, UPOS=DET, FEATS=Definite=Def|Number=Plur|PronType=Art 116\n",
      "De, Lemma=de, UPOS=PRON, FEATS=Case=Nom|Definite=Def|Number=Plur|PronType=Prs 91\n",
      "de, Lemma=en, UPOS=PRON, FEATS=Case=Nom|Definite=Def|Number=Plur|PronType=Prs 12\n",
      "de, Lemma=de, UPOS=DET, FEATS=Definite=Def|Number=Plur|PronType=Prs 7\n",
      "De, Lemma=de, UPOS=DET, FEATS=Definite=Def|Number=Plur|PronType=Prs 2\n",
      "de, Lemma=de, UPOS=PROPN, FEATS=Case=Nom 2\n",
      "de, Lemma=de, UPOS=PRON, FEATS=Case=Nom|Definite=Def|Number=Plur|PronType=Ind 1\n",
      "de, Lemma=de, UPOS=PRON, FEATS=Case=Nom|Definite=Def|Number=Plur|PronType=Rel 1\n",
      "\n",
      "den, Lemma=en, UPOS=DET, FEATS=Definite=Def|Gender=Com|Number=Sing|PronType=Art 662\n",
      "den, Lemma=den, UPOS=PRON, FEATS=Definite=Def|Gender=Com|Number=Sing|PronType=Prs 163\n",
      "Den, Lemma=en, UPOS=DET, FEATS=Definite=Def|Gender=Com|Number=Sing|PronType=Art 152\n",
      "Den, Lemma=den, UPOS=PRON, FEATS=Definite=Def|Gender=Com|Number=Sing|PronType=Prs 71\n",
      "den, Lemma=en, UPOS=PRON, FEATS=Definite=Def|Gender=Com|Number=Sing|PronType=Prs 16\n",
      "den, Lemma=den, UPOS=DET, FEATS=Definite=Def|Gender=Com|Number=Sing|PronType=Prs 9\n",
      "den, Lemma=en, UPOS=PRON, FEATS=Definite=Def|Number=Plur|PronType=Prs 2\n",
      "den, Lemma=den, UPOS=PRON, FEATS=Definite=Def|Number=Plur|PronType=Prs 1\n",
      "\n",
      "det, Lemma=den, UPOS=PRON, FEATS=Definite=Def|Gender=Neut|Number=Sing|PronType=Prs 741\n",
      "Det, Lemma=den, UPOS=PRON, FEATS=Definite=Def|Gender=Neut|Number=Sing|PronType=Prs 401\n",
      "det, Lemma=en, UPOS=DET, FEATS=Definite=Def|Gender=Neut|Number=Sing|PronType=Art 273\n",
      "Det, Lemma=en, UPOS=DET, FEATS=Definite=Def|Gender=Neut|Number=Sing|PronType=Art 47\n",
      "det, Lemma=den, UPOS=DET, FEATS=Definite=Def|Gender=Neut|Number=Sing|PronType=Prs 12\n",
      "det, Lemma=en, UPOS=PRON, FEATS=Definite=Def|Gender=Neut|Number=Sing|PronType=Prs 4\n",
      "Det, Lemma=det, UPOS=PRON, FEATS=Definite=Def|Gender=Neut|Number=Sing|PronType=Prs 2\n",
      "Det, Lemma=den, UPOS=DET, FEATS=Definite=Def|Gender=Neut|Number=Sing|PronType=Prs 1\n",
      "Det, Lemma=den, UPOS=PRON, FEATS=Definite=Def|Gender=Neut|Number=Sing|PronType=Art 1\n",
      "det, Lemma=den, UPOS=PRON, FEATS=Definite=Def|Gender=Neut|Number=Sing|PronType=Ind 1\n",
      "det, Lemma=det, UPOS=DET, FEATS=Definite=Def|Gender=Neut|Number=Sing|PronType=Prs 1\n",
      "det, Lemma=den, UPOS=PRON, FEATS=Definite=Def|Gender=Neut|Number=Sing|PronType=Tot 1\n"
     ]
    }
   ],
   "source": [
    "descrs = findDescriptions (udpath, talbfiles, ['de', 'den', 'det'])\n",
    "\n",
    "descrs\n",
    "for wrd in descrs:\n",
    "    print()\n",
    "    for desc in descrs[wrd].most_common():\n",
    "        print(desc[0], desc[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "204d8975-3ca9-46d0-90a9-d4e12782ea92",
   "metadata": {},
   "source": [
    "In the future these words should carry the following lemmas and features:\n",
    " - den, Den with UPOS DET; Lemma: den; Feats: Definite=Def|Gender=Com|Number=Sing|PronType=Art\n",
    " - den, Den with UPOS PRON; Lemma: den; Feats: Definite=Def|Gender=Com|Number=Sing|PronType=Prs\n",
    " \n",
    " - det, Det with UPOS DET; Lemma: den; Feats: Definite=Def|Gender=Neut|Number=Sing|PronType=Art\n",
    " - det, Det with UPOS PRON; Lemma: den; Feats: Definite=Def|Gender=Neut|Number=Sing|PronType=Prs\n",
    " \n",
    " - de, De with UPOS DET; Lemma: de; Feats: Definite=Def|Number=Plur|PronType=Art\n",
    " - dom, Dom with UPOS DET; Lemma: de; Feats: Definite=Def|Number=Plur|PronType=Art\n",
    " - de, De with UPOS PRON; Lemma: de; Feats: Case=Nom|Definite=Def|Number=Plur|PronType=Prs\n",
    " \n",
    " - dem, Dem with UPOS PRON; Lemma: de; Feats: Case=Acc|Definite=Def|Number=Plur|PronType=Prs\n",
    " - dom, Dom with UPOS PRON; Lemma: de; Feats: Definite=Def|Number=Plur|PronType=Prs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d43016ee-73fc-40ba-abbd-61715006178f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def setNewAnnotation (udfile, outfile, tokenlist, upos, lemmadict, featsdict):\n",
    "    ''' writes a changed annotation from <udfile> to <outfile> using a <UPOS> and dictionaries with new values '''\n",
    "    \n",
    "    changes = Counter()\n",
    "    for tok in tokenlist:\n",
    "        changes[tok] = 0\n",
    "        \n",
    "    with open (outfile, \"w\") as w:\n",
    "        with open (udfile, \"r\") as u:\n",
    "            for line in u:\n",
    "                if re.match(r'\\d', line):\n",
    "                    info = line.strip().split('\\t')\n",
    "                    if (info[1] in tokenlist) and (info[3]==upos):\n",
    "                        if (info[2] != lemmadict[info[1]]) or (info[5] != featsdict[info[1]]):\n",
    "                            info[2] = lemmadict[info[1]]\n",
    "                            info[5] = featsdict[info[1]]\n",
    "                            newline = '\\t'.join(info) + '\\n'\n",
    "                            changes[info[1]] += 1\n",
    "                            w.write(newline)\n",
    "                        else:\n",
    "                            w.write(line)                    \n",
    "                    else:\n",
    "                        w.write(line)\n",
    "                else:\n",
    "                    w.write(line)\n",
    "    w.close()\n",
    "    return changes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "abf513de-b0d2-4e50-8cbe-be60c9e16d58",
   "metadata": {},
   "outputs": [],
   "source": [
    "detlemmadict = {'den': 'den', 'Den':'den', 'det':'den', 'Det':'den', 'de':'de', 'De':'de', 'dom':'de', 'Dom':'de'}\n",
    "pronlemmadict = {'den': 'den', 'Den':'den', 'det':'den', 'Det':'den', 'de':'de', 'De':'de', 'dom':'de', 'Dom':'de', 'dem':'de'}\n",
    "detfeatsdict = {'den': 'Definite=Def|Gender=Com|Number=Sing|PronType=Art', \n",
    "                'Den':'Definite=Def|Gender=Com|Number=Sing|PronType=Art',\n",
    "                'det':'Definite=Def|Gender=Neut|Number=Sing|PronType=Art', \n",
    "                'Det':'Definite=Def|Gender=Neut|Number=Sing|PronType=Art', \n",
    "                'de':'Definite=Def|Number=Plur|PronType=Art', \n",
    "                'De':'Definite=Def|Number=Plur|PronType=Art', \n",
    "                'dom':'Definite=Def|Number=Plur|PronType=Art', \n",
    "                'Dom':'Definite=Def|Number=Plur|PronType=Art'}\n",
    "pronfeatsdict = {'den': 'Definite=Def|Gender=Com|Number=Sing|PronType=Prs', \n",
    "                'Den':'Definite=Def|Gender=Com|Number=Sing|PronType=Prs',\n",
    "                'det':'Definite=Def|Gender=Neut|Number=Sing|PronType=Prs', \n",
    "                'Det':'Definite=Def|Gender=Neut|Number=Sing|PronType=Prs', \n",
    "                'de':'Case=Nom|Definite=Def|Number=Plur|PronType=Prs', \n",
    "                'De':'Case=Nom|Definite=Def|Number=Plur|PronType=Prs', \n",
    "                'dom':'Definite=Def|Number=Plur|PronType=Prs', \n",
    "                'Dom':'Definite=Def|Number=Plur|PronType=Prs', \n",
    "                'dem':'Case=Acc|Definite=Def|Number=Plur|PronType=Prs'}\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89e3f0c6-62df-4f23-8c98-06d7944f63f2",
   "metadata": {},
   "source": [
    "We test before doing it permanently..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7a2cee49-b4fa-428e-87b1-97dbabb4b363",
   "metadata": {},
   "outputs": [],
   "source": [
    "trialfiles = ['trial_240105-dev.conllu', 'trial_240105-test.conllu', 'trial_240105-train.conllu']\n",
    "devresult = setNewAnnotation(trialfiles[0], 'trial-dev.conllu', pronlemmadict.keys(), 'PRON', pronlemmadict, pronfeatsdict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "050c4ab8-5e5b-45eb-8408-bbaae30d8234",
   "metadata": {},
   "outputs": [],
   "source": [
    "testresult = setNewAnnotation(trialfiles[1], 'trial-test.conllu', pronlemmadict.keys(), 'PRON', pronlemmadict, pronfeatsdict)\n",
    "trainresult = setNewAnnotation(trialfiles[2], 'trial-train.conllu', pronlemmadict.keys(), 'PRON', pronlemmadict, pronfeatsdict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6371335c-3467-41ec-b3df-586a686946a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'dom': 17, 'den': 3, 'Dom': 3, 'de': 1, 'Den': 0, 'det': 0, 'Det': 0, 'De': 0, 'dem': 0}) \n",
      " Counter({'det': 8, 'dom': 7, 'den': 2, 'Den': 1, 'de': 1, 'Dom': 1, 'Det': 0, 'De': 0, 'dem': 0}) \n",
      " Counter({'den': 125, 'Den': 24, 'dom': 13, 'Dom': 4, 'det': 3, 'de': 2, 'Det': 0, 'De': 0, 'dem': 0})\n"
     ]
    }
   ],
   "source": [
    "print(devresult, '\\n', testresult, '\\n', trainresult)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f74bc6fa-25aa-4e14-87fc-d76d56fee62f",
   "metadata": {},
   "source": [
    "We can then check the result using *findDescriptions*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "194d4c8a-d877-471c-b04f-d7c257719c28",
   "metadata": {},
   "source": [
    "### Setting new features for adjectives"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c2b298a-3cf8-42aa-945d-5b65452cf86a",
   "metadata": {},
   "source": [
    "We have arrived at the following principles for annotation of ADJ features:\n",
    "\n",
    "    - Base forms such as STOR: Case=Nom|Definite=Ind|Degree=Pos|Gender=Com|Number=Sing\n",
    "    - Singular, neuter forms: STOR-t: Case=Nom|Definite=Ind|Degree=Pos|Gender=Neut|Number=Sing\n",
    "As a rule there are two alternatives for forms ending in *-a* or *-e*:\n",
    "\n",
    "    - if definite: Case=Nom|Definite=Def|Degree=Pos \n",
    "    - if indefinite, plural: Case=Nom|Definite=Ind|Degree=Pos|Number=Plur\n",
    "Om adjektivet har samma form i utrum och neutrum, som SVART faller **Gender** bort. Om det har samma form i bestämd och obestämd form, som GRÅ, faller **Definite** bort, och vid samma form i singularis och pluralis, som BRA, faller dessutom **Number** bort.\n",
    "\n",
    "Om adjektivet är komparerat: STÖRRE: **Case=Nom|Degree=Cmp**\n",
    "\n",
    "Om adjektivet står i superlativ finns två former, STÖRST: **Case=Nom|Definite=Ind|Degree=Sup** och STÖRSTA: **Case=Nom|Definite=Def|Degree=Sup**\n",
    "\n",
    "Om adjektivet står i genitiv gäller för alla fall att Case=Nom ersätts med: **Case=Gen**\n",
    "\n",
    "Ordningstal som TREDJE eller ELFTE anses inte kunna kompareras och annoteras: **Case=Nom|Number=Sing|NumType=Ord**\n",
    "    \n",
    "Presens participformer så som *bedårande*: **Case=Nom|Degree=Pos|Tense=Pres|VerbForm=Part**\n",
    "\n",
    "Perfekt participformer som *fruktad*, *berömd*:\n",
    "\n",
    "    - sing. obestämd, FRUKTA-d: Case=Nom|Definite=Ind|Degree=Pos|Gender=Com|Number=Sing|Tense=Past|VerbForm=Part\n",
    "    - sing, obestämd, FRUKTA-t: Case=Nom|Definite=Ind|Degree=Pos|Gender=Neut|Number=Sing|Tense=Past|VerbForm=Part\n",
    "    - plur obestämd, FRUKTA-de: Case=Nom|Definite=Ind|Degree=Pos|Number=Plur|Tense=Past|VerbForm=Part, eller\n",
    "    - best., den/det/de FRUKTA-de: Case=Nom|Definite=Def|Degree=Pos|Tense=Past|VerbForm=Part\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "982cd159-33fa-4621-b63f-61e541910427",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def extractProps(proplist):\n",
    "    ''' this extracts info from a complete token description '''\n",
    "    retlist = [proplist[1], proplist[2], proplist[3]]\n",
    "    if proplist[3] == 'DET':\n",
    "        matchObj1 = re.search(r'Definite=(\\w\\w\\w)', proplist[5])\n",
    "        matchObj2 = re.search(r'Number=(\\w\\w\\w\\w?)', proplist[5])\n",
    "        matchObj3 = re.search(r'Gender=(\\w\\w\\w\\w?)', proplist[5])\n",
    "        if matchObj1:\n",
    "            retlist.append(matchObj1.group(1))\n",
    "        if matchObj2:\n",
    "            retlist.append(matchObj2.group(1))\n",
    "            if matchObj2.group(1) == 'Sing' and matchObj3:\n",
    "                retlist.append(matchObj3.group(1))\n",
    "    elif re.search(r'Poss=Yes', proplist[4]):\n",
    "        retlist.append('Poss')\n",
    "        matchObj1 = re.search(r'Number=(\\w\\w\\w\\w?)', proplist[5])\n",
    "        matchObj2 = re.search(r'Gender=(\\w\\w\\w\\w?)', proplist[5])\n",
    "        if matchObj1:\n",
    "            retlist.append(matchObj1.group(1))\n",
    "            if matchObj1.group(1) == 'Sing' and matchObj2:\n",
    "                retlist.append(matchObj2.group(1))\n",
    "    elif proplist[3] == 'NOUN':\n",
    "        matchObj1 = re.search(r'Number=(\\w\\w\\w\\w?)', proplist[5])\n",
    "        matchObj2 = re.search(r'Gender=(\\w\\w\\w\\w?)', proplist[5])\n",
    "        if matchObj1:\n",
    "            retlist.append(matchObj1.group(1))\n",
    "            if matchObj1.group(1) == 'Sing' and matchObj2:\n",
    "                retlist.append(matchObj2.group(1))\n",
    "    elif proplist[4] == 'ORD':\n",
    "        retlist.append('Ord')\n",
    "    return retlist\n",
    "\n",
    "def createFeats (feats, myprops, sentprops):\n",
    "    ''' returns new features for adjectives, not complete and will miss several tokens that are now annotated wrongly '''\n",
    "    \n",
    "    if (myprops[0][-1] in ['f', 'g', 'l', 'm', 'n', 'p', 'r', 's', 'v']) and (myprops[0] == myprops[1]+'t'):\n",
    "        nfeats = 'Case=Nom|Definite=Ind|Degree=Pos|Gender=Neut|Number=Sing'\n",
    "    elif myprops[0][-2:] == 'ad' and myprops[1].endswith('a'):\n",
    "        nfeats = 'Case=Nom|Definite=Ind|Degree=Pos|Gender=Com|Number=Sing|Tense=Past|VerbForm=Part'\n",
    "    elif (myprops[0][-3:] == 'ade') and ((myprops[1].endswith('a')) or (myprops[1].endswith('d'))):\n",
    "        if re.search(r'Plur', feats):\n",
    "            nfeats = 'Case=Nom|Definite=Ind|Degree=Pos|Number=Plur|Tense=Past|VerbForm=Part'\n",
    "        else: \n",
    "            nfeats = 'Case=Nom|Definite=Def|Degree=Pos|Tense=Past|VerbForm=Part'        \n",
    "    elif myprops[0][-2:] == 'at' and ((myprops[1].endswith('a')) or (myprops[1].endswith('d'))):\n",
    "        nfeats = 'Case=Nom|Definite=Ind|Degree=Pos|Gender=Neut|Number=Sing|Tense=Past|VerbForm=Part'\n",
    "    elif myprops[0][-3:] == 'sta' and re.search(r'Sup', feats):\n",
    "        nfeats = 'Case=Nom|Definite=Def|Degree=Sup'\n",
    "    elif myprops[0][-2:] == 'st' and re.search(r'Sup', feats):\n",
    "        nfeats = 'Case=Nom|Definite=Ind|Degree=Sup'\n",
    "    elif myprops[0][-2:] == 're' and re.search(r'Cmp', feats):\n",
    "        nfeats = 'Case=Nom|Degree=Cmp'\n",
    "    elif myprops[0][-3:] != 'sta' and myprops[0] == myprops[1] + 'a' and re.search(r'=Def', feats):\n",
    "        nfeats = 'Case=Nom|Definite=Def|Degree=Pos'\n",
    "    elif myprops[0][-3:] != 'sta' and myprops[0] == myprops[1] + 'a' and re.search(r'Plur', feats):\n",
    "        nfeats = 'Case=Nom|Definite=Ind|Degree=Pos|Number=Plur'\n",
    "    elif myprops[-1] == 'Ord':\n",
    "        nfeats = 'Case=Nom|Number=Sing|NumType=Ord'\n",
    "    elif myprops[0][-3:] == 'nde':\n",
    "        nfeats = 'Case=Nom|Degree=Pos|Tense=Pres|VerbForm=Part'\n",
    "    else:\n",
    "        nfeats = feats\n",
    "    return nfeats\n",
    "\n",
    "                \n",
    "def changeAdjFeats (svudfile, outfile, newfeatsdict, stopix):\n",
    "    ''' Writes updated features for ADJs to <OUTFILE> given feats collected from the function createFeats '''\n",
    "    ''' The last parameter is used for breaking reading the input file '''\n",
    "    oldfeats = {}\n",
    "    oldinfo = {}\n",
    "    newfeats = {}\n",
    "    changes = 0\n",
    "    adjix = 0\n",
    "    six = 0\n",
    "    \n",
    "    with open (outfile, \"w\") as w:\n",
    "        with open (svudfile, \"r\") as f:\n",
    "            props = defaultdict()\n",
    "            for line in f:\n",
    "                line = line.rstrip()\n",
    "                if len(line) == 0:\n",
    "                    for ix in props:\n",
    "                        if props[ix][2] == 'ADJ':\n",
    "                            adjix += 1\n",
    "                            oldfeats[adjix] = oldfeats[ix]\n",
    "                            newfeats[adjix] = createFeats(oldfeats[ix], props[ix], props)\n",
    "                            \n",
    "                            if newfeats[adjix] != oldfeats[adjix]:\n",
    "                                changes += 1\n",
    "                            newinfo = oldinfo[ix]\n",
    "                            newinfo[5] = newfeats[adjix]\n",
    "                            w.write('\\t'.join(newinfo))\n",
    "                            w.write('\\n')\n",
    "                        else:\n",
    "                            w.write('\\t'.join(oldinfo[ix]))\n",
    "                            w.write('\\n')\n",
    "                    w.write('\\n')        \n",
    "                    props = defaultdict()\n",
    "                elif re.match(r'\\d', line):\n",
    "                    six += 1\n",
    "                    #if six == stopix:\n",
    "                        #break\n",
    "                    info = line.split('\\t')\n",
    "                    oldfeats[info[0]] = info[5]\n",
    "                    oldinfo[info[0]] = info\n",
    "                    props[info[0]] = extractProps(info)\n",
    "                else:\n",
    "                    w.write(line+'\\n')\n",
    "        f.close()\n",
    "    w.close()\n",
    "    return oldfeats, newfeats, adjix, changes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc7d6cd0-afdf-4460-b8c4-85db65c1d048",
   "metadata": {},
   "source": [
    "An example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ed8c925c-516e-4c8b-afa8-cab8db885ad8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Have read 1257 adjectives, and changed 322\n"
     ]
    }
   ],
   "source": [
    "oldstuff, newstuff, adjs, changed = changeAdjFeats ('trial_240106-dev.conllu', 'trial-dev.conllu', {}, 1000)\n",
    "print('\\nHave read', adjs, 'adjectives, and changed', changed)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
